{"ast":null,"code":"// Note: Web-based speech recognition is limited compared to server-side solutions\n// This is a simplified implementation that uses the Web Speech API\n\nexport const transcribeAudio = async audioFile => {\n  // For audio file transcription, we'd typically need to send the file to a backend service\n  // since browser APIs are limited for handling audio files\n\n  // As a fallback for demonstration, we'll check if we can use the browser's SpeechRecognition API\n  if (audioFile instanceof File) {\n    // In a real app, you would upload this file to your server and process it there\n    // or use a service like Google Speech-to-Text API\n\n    // For demonstration purposes only:\n    return new Promise((resolve, reject) => {\n      // In a real app, this would be replaced with a fetch call to a backend endpoint\n      // that handles audio transcription\n      setTimeout(() => {\n        resolve(\"This is a placeholder transcript. In a real application, the audio file would be sent to a server for transcription using a service like Google Speech-to-Text API.\");\n      }, 2000);\n    });\n  }\n\n  // For live transcription (not from a file)\n  return new Promise((resolve, reject) => {\n    // Check if browser supports speech recognition\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      reject(new Error(\"Your browser doesn't support speech recognition. Try a different browser or upload an audio file.\"));\n      return;\n    }\n    const recognition = new SpeechRecognition();\n    recognition.lang = \"en-US\";\n    recognition.continuous = true;\n    recognition.interimResults = false;\n    let finalTranscript = \"\";\n    recognition.onresult = event => {\n      for (let i = event.resultIndex; i < event.results.length; i++) {\n        if (event.results[i].isFinal) {\n          finalTranscript += event.results[i][0].transcript + \" \";\n        }\n      }\n    };\n    recognition.onerror = event => {\n      recognition.stop();\n      reject(new Error(`Speech recognition error: ${event.error}`));\n    };\n    recognition.onend = () => {\n      resolve(finalTranscript.trim() || \"No speech was detected. Please try again.\");\n    };\n    recognition.start();\n\n    // Automatically stop after 10 seconds (for short recordings)\n    setTimeout(() => {\n      recognition.stop();\n    }, 10000);\n  });\n};","map":{"version":3,"names":["transcribeAudio","audioFile","File","Promise","resolve","reject","setTimeout","SpeechRecognition","window","webkitSpeechRecognition","Error","recognition","lang","continuous","interimResults","finalTranscript","onresult","event","i","resultIndex","results","length","isFinal","transcript","onerror","stop","error","onend","trim","start"],"sources":["E:/LETU/Transcript-Notes/Transcript-Notes/react-transcript-notes/src/services/transcriptionService.js"],"sourcesContent":["// Note: Web-based speech recognition is limited compared to server-side solutions\r\n// This is a simplified implementation that uses the Web Speech API\r\n\r\nexport const transcribeAudio = async (audioFile) => {\r\n  // For audio file transcription, we'd typically need to send the file to a backend service\r\n  // since browser APIs are limited for handling audio files\r\n\r\n  // As a fallback for demonstration, we'll check if we can use the browser's SpeechRecognition API\r\n  if (audioFile instanceof File) {\r\n    // In a real app, you would upload this file to your server and process it there\r\n    // or use a service like Google Speech-to-Text API\r\n\r\n    // For demonstration purposes only:\r\n    return new Promise((resolve, reject) => {\r\n      // In a real app, this would be replaced with a fetch call to a backend endpoint\r\n      // that handles audio transcription\r\n      setTimeout(() => {\r\n        resolve(\r\n          \"This is a placeholder transcript. In a real application, the audio file would be sent to a server for transcription using a service like Google Speech-to-Text API.\"\r\n        );\r\n      }, 2000);\r\n    });\r\n  }\r\n\r\n  // For live transcription (not from a file)\r\n  return new Promise((resolve, reject) => {\r\n    // Check if browser supports speech recognition\r\n    const SpeechRecognition =\r\n      window.SpeechRecognition || window.webkitSpeechRecognition;\r\n\r\n    if (!SpeechRecognition) {\r\n      reject(\r\n        new Error(\r\n          \"Your browser doesn't support speech recognition. Try a different browser or upload an audio file.\"\r\n        )\r\n      );\r\n      return;\r\n    }\r\n\r\n    const recognition = new SpeechRecognition();\r\n    recognition.lang = \"en-US\";\r\n    recognition.continuous = true;\r\n    recognition.interimResults = false;\r\n\r\n    let finalTranscript = \"\";\r\n\r\n    recognition.onresult = (event) => {\r\n      for (let i = event.resultIndex; i < event.results.length; i++) {\r\n        if (event.results[i].isFinal) {\r\n          finalTranscript += event.results[i][0].transcript + \" \";\r\n        }\r\n      }\r\n    };\r\n\r\n    recognition.onerror = (event) => {\r\n      recognition.stop();\r\n      reject(new Error(`Speech recognition error: ${event.error}`));\r\n    };\r\n\r\n    recognition.onend = () => {\r\n      resolve(\r\n        finalTranscript.trim() || \"No speech was detected. Please try again.\"\r\n      );\r\n    };\r\n\r\n    recognition.start();\r\n\r\n    // Automatically stop after 10 seconds (for short recordings)\r\n    setTimeout(() => {\r\n      recognition.stop();\r\n    }, 10000);\r\n  });\r\n};\r\n"],"mappings":"AAAA;AACA;;AAEA,OAAO,MAAMA,eAAe,GAAG,MAAOC,SAAS,IAAK;EAClD;EACA;;EAEA;EACA,IAAIA,SAAS,YAAYC,IAAI,EAAE;IAC7B;IACA;;IAEA;IACA,OAAO,IAAIC,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;MACtC;MACA;MACAC,UAAU,CAAC,MAAM;QACfF,OAAO,CACL,qKACF,CAAC;MACH,CAAC,EAAE,IAAI,CAAC;IACV,CAAC,CAAC;EACJ;;EAEA;EACA,OAAO,IAAID,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;IACtC;IACA,MAAME,iBAAiB,GACrBC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;IAE5D,IAAI,CAACF,iBAAiB,EAAE;MACtBF,MAAM,CACJ,IAAIK,KAAK,CACP,mGACF,CACF,CAAC;MACD;IACF;IAEA,MAAMC,WAAW,GAAG,IAAIJ,iBAAiB,CAAC,CAAC;IAC3CI,WAAW,CAACC,IAAI,GAAG,OAAO;IAC1BD,WAAW,CAACE,UAAU,GAAG,IAAI;IAC7BF,WAAW,CAACG,cAAc,GAAG,KAAK;IAElC,IAAIC,eAAe,GAAG,EAAE;IAExBJ,WAAW,CAACK,QAAQ,GAAIC,KAAK,IAAK;MAChC,KAAK,IAAIC,CAAC,GAAGD,KAAK,CAACE,WAAW,EAAED,CAAC,GAAGD,KAAK,CAACG,OAAO,CAACC,MAAM,EAAEH,CAAC,EAAE,EAAE;QAC7D,IAAID,KAAK,CAACG,OAAO,CAACF,CAAC,CAAC,CAACI,OAAO,EAAE;UAC5BP,eAAe,IAAIE,KAAK,CAACG,OAAO,CAACF,CAAC,CAAC,CAAC,CAAC,CAAC,CAACK,UAAU,GAAG,GAAG;QACzD;MACF;IACF,CAAC;IAEDZ,WAAW,CAACa,OAAO,GAAIP,KAAK,IAAK;MAC/BN,WAAW,CAACc,IAAI,CAAC,CAAC;MAClBpB,MAAM,CAAC,IAAIK,KAAK,CAAC,6BAA6BO,KAAK,CAACS,KAAK,EAAE,CAAC,CAAC;IAC/D,CAAC;IAEDf,WAAW,CAACgB,KAAK,GAAG,MAAM;MACxBvB,OAAO,CACLW,eAAe,CAACa,IAAI,CAAC,CAAC,IAAI,2CAC5B,CAAC;IACH,CAAC;IAEDjB,WAAW,CAACkB,KAAK,CAAC,CAAC;;IAEnB;IACAvB,UAAU,CAAC,MAAM;MACfK,WAAW,CAACc,IAAI,CAAC,CAAC;IACpB,CAAC,EAAE,KAAK,CAAC;EACX,CAAC,CAAC;AACJ,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}